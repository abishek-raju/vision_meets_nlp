{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDR_MAGIC = b\"LITPKDS\"\n",
    "HDR_SIZE = 24  # bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(HDR_MAGIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {1: np.uint8, 2: np.int8, 3: np.int16, 4: np.int32, 5: np.int64, 6: np.float32, 7: np.float64, 8: np.uint16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PackedDatasetIterator:\n",
    "    def __init__(self, filenames, n_chunks, block_size):\n",
    "\n",
    "        self._block_idxs = None\n",
    "\n",
    "        self._filenames = filenames\n",
    "        self._file_idx = 0\n",
    "\n",
    "        self._n_chunks = n_chunks\n",
    "\n",
    "        self._dtype = None\n",
    "        self._block_size = block_size\n",
    "        self._n_blocks = None\n",
    "\n",
    "        self._mmaps = []\n",
    "        self._buffers = []\n",
    "\n",
    "        self._block_idxs = []\n",
    "        self._curr_idx = 0\n",
    "\n",
    "        self._load_n_chunks()\n",
    "    \n",
    "    def _load_n_chunks(self):\n",
    "        self._close_mmaps()\n",
    "        self._mmaps = []\n",
    "        self._buffers = []\n",
    "\n",
    "        if self._n_chunks > len(self._filenames[self._file_idx :]):\n",
    "            self._file_idx = 0\n",
    "\n",
    "        for i in range(self._n_chunks):\n",
    "            filename = self._filenames[self._file_idx + i]\n",
    "            # print(\"filename :\",filename)\n",
    "            # print(\"i :\",i)\n",
    "            if self._dtype is None:\n",
    "                self._dtype, self._chunk_size = self._read_header(filename)\n",
    "                self._n_blocks = self._chunk_size // self._block_size\n",
    "            # TODO: check header matches with previous files\n",
    "            mmap = np.memmap(filename, mode=\"r\", order=\"C\", offset=HDR_SIZE)\n",
    "            self._mmaps.append(mmap)\n",
    "            self._buffers.append(memoryview(mmap))\n",
    "\n",
    "        self._file_idx += self._n_chunks\n",
    "        n_all_blocks = self._n_chunks * self._n_blocks\n",
    "\n",
    "        # self._block_idxs = self._rng.permutation(n_all_blocks) if self._shuffle else range(n_all_blocks)\n",
    "\n",
    "        self._block_idxs = range(n_all_blocks)\n",
    "\n",
    "        self._curr_idx = 0\n",
    "    \n",
    "    def _close_mmaps(self):\n",
    "        for mmap in self._mmaps:\n",
    "            mmap._mmap.close()\n",
    "    \n",
    "    def _read_header(self, path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            magic = f.read(len(HDR_MAGIC))\n",
    "            print(magic)\n",
    "            assert magic == HDR_MAGIC, \"File doesn't match expected format.\"\n",
    "            version = struct.unpack(\"<Q\", f.read(8))\n",
    "            assert version == (1,)\n",
    "            (dtype_code,) = struct.unpack(\"<B\", f.read(1))\n",
    "            dtype = dtypes[dtype_code]\n",
    "            (chunk_size,) = struct.unpack(\"<Q\", f.read(8))\n",
    "        return dtype, chunk_size\n",
    "    \n",
    "    def __del__(self):\n",
    "        self._close_mmaps()\n",
    "        del self._mmaps\n",
    "        del self._buffers\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self._curr_idx >= len(self._block_idxs):\n",
    "            self._load_n_chunks()\n",
    "            # TODO: trigger fetching next next n_chunks if remote\n",
    "        block_idx = self._block_idxs[self._curr_idx]\n",
    "        chunk_id = block_idx // self._n_blocks\n",
    "        buffer = self._buffers[chunk_id]\n",
    "        elem_id = (block_idx % self._n_blocks) * self._block_size\n",
    "        offset = np.dtype(self._dtype).itemsize * elem_id\n",
    "        arr = np.frombuffer(buffer, dtype=self._dtype, count=self._block_size, offset=offset)\n",
    "        self._curr_idx += 1\n",
    "        return torch.from_numpy(arr.astype(np.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = [\n",
    "    (\"arxiv\", 2.5),\n",
    "    (\"book\", 4.5),\n",
    "    (\"c4\", 15.0),\n",
    "    (\"cc\", 67.0),\n",
    "    (\"github\", 4.5),\n",
    "    (\"stackexchange\", 2.0),\n",
    "    (\"wikipedia\", 4.5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"arxiv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"./data/RedPajama-Data-1T-Sample/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"/home/rampfire/Downloads/data/lit-redpajama-sample/ar*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'LITPKDS'\n"
     ]
    }
   ],
   "source": [
    "temp = PackedDatasetIterator(filenames,\n",
    "                        4,\n",
    "                        4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PackedDataset(IterableDataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        return PackedDatasetIterator(filenames,\n",
    "                        4,\n",
    "                        2049)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = PackedDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_data,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'LITPKDS'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2049])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_dataloader)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('pytorch_model_training')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "639cd7b51718eb79982c53fc18e7f7b25ec7e9a2a775b00e4c4cd00fb053d272"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
