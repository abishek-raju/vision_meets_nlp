{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chars = \"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [i for i in all_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "# print(encode(\"hii there\"))\n",
    "# print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rampfire/anaconda3/envs/pytorch_model_training/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/rampfire/ERA__V_1/vision_meets_nlp')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import hydra\n",
    "import lightning as L\n",
    "import pyrootutils\n",
    "import torch\n",
    "from lightning import Callback, LightningDataModule, LightningModule, Trainer\n",
    "from lightning.pytorch.loggers import Logger\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "pyrootutils.setup_root(os.getcwd(), indicator=\".project-root\", pythonpath=True)\n",
    "# from src import utils\n",
    "\n",
    "# log = utils.get_pylogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8195/1090264794.py:4: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path=\"../../configs\", job_name=\"test_app\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name: train\n",
      "tags:\n",
      "- llm\n",
      "- nanogpt\n",
      "train: true\n",
      "test: false\n",
      "compile: false\n",
      "ckpt_path: null\n",
      "seed: 12345\n",
      "data:\n",
      "  _target_: src.data.tinyshakespearedatamodule.TinyShakespeareDataloader\n",
      "  data_dir: ${paths.data_dir}\n",
      "  batch_size: 256\n",
      "  train_val_test_split:\n",
      "  - 55000\n",
      "  - 5000\n",
      "  - 10000\n",
      "  num_workers: 4\n",
      "  pin_memory: false\n",
      "model:\n",
      "  _target_: src.models.bigram_language_pl.BigramLanguageModelLitModule\n",
      "  vocab_size: 65\n",
      "  optimizer:\n",
      "    _target_: torch.optim.Adam\n",
      "    _partial_: true\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      "  scheduler: null\n",
      "callbacks:\n",
      "  model_checkpoint:\n",
      "    _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: epoch_{epoch:03d}\n",
      "    monitor: val/acc\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 1\n",
      "    mode: max\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  early_stopping:\n",
      "    _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "    monitor: val/acc\n",
      "    min_delta: 0.0\n",
      "    patience: 100\n",
      "    verbose: false\n",
      "    mode: max\n",
      "    strict: true\n",
      "    check_finite: true\n",
      "    stopping_threshold: null\n",
      "    divergence_threshold: null\n",
      "    check_on_train_epoch_end: null\n",
      "  model_summary:\n",
      "    _target_: lightning.pytorch.callbacks.RichModelSummary\n",
      "    max_depth: -1\n",
      "  rich_progress_bar:\n",
      "    _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "logger:\n",
      "  tensorboard:\n",
      "    _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger\n",
      "    save_dir: ${paths.output_dir}/tensorboard/\n",
      "    name: null\n",
      "    log_graph: false\n",
      "    default_hp_metric: true\n",
      "    prefix: ''\n",
      "  wandb:\n",
      "    tags: ${tags}\n",
      "    group: cifar\n",
      "  aim:\n",
      "    experiment: cifar\n",
      "trainer:\n",
      "  _target_: lightning.pytorch.trainer.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 0\n",
      "  max_epochs: 1\n",
      "  accelerator: cpu\n",
      "  devices: 1\n",
      "  check_val_every_n_epoch: 1\n",
      "  deterministic: false\n",
      "  gradient_clip_val: 0.5\n",
      "  fast_dev_run: true\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_ROOT}\n",
      "  data_dir: ${paths.root_dir}/data/\n",
      "  log_dir: ${paths.root_dir}/logs/\n",
      "  output_dir: ${hydra:runtime.output_dir}\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "extras:\n",
      "  ignore_warnings: false\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "print_mean_and_std: false\n",
      "visualizations:\n",
      "  generate: false\n",
      "  display_number_of_sample: 10\n",
      "  each_epoch_visualization: true\n",
      "  generate_output_images: false\n",
      "  correctly_identified: 10\n",
      "  incorrectly_identified: 10\n",
      "  sample_set_output: 10\n",
      "find_lr:\n",
      "  find_lr: false\n",
      "  end_lr: 10\n",
      "  num_iter: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(config_path=\"../../configs\", job_name=\"test_app\")\n",
    "cfg = compose(config_name=\"train.yaml\", overrides=[\"experiment=gpt/gpt.yaml\"])\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: LightningModule = hydra.utils.instantiate(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"/home/rampfire/ERA__V_1/vision_meets_nlp/logs/train/runs/last_gpt.ckpt\",map_location=torch.device('cpu'))\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "# idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 47, 47, 1, 58, 46, 43, 56, 43]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoded_sample = encode(\"hii there\")\n",
    "# encoded_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[46, 47, 47,  1, 58, 46, 43, 56, 43]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = torch.tensor([encoded_sample], dtype=torch.long)\n",
    "# data,data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii thereleeoulbre hnouspouat ce t tse tonsp w tobe O the thee w tosewoff y ht m. w ap tshe the offf-ng sow s---- y are bu, y the busche totre mp Ce\n",
      "\n",
      " medne y to----he itw tne a ppon y tp che me the tstoupeng cre offuse che, te se\n",
      "\n",
      "\n",
      "\n",
      "the y tithese ty titre tme ine itshnse ce ate\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " kipp ssp thawe itoe ido-che t-- ip w the taf tone twonsp me a tw ve tsp sp-- ch tonome w he tw\n",
      " tofonobShe fon ship me tche a ing a o--shife it ofibee w mimishe m? mme a je mp\n",
      " thi h swe atod e sp y ta-ffThe w sp te y tofof \n"
     ]
    }
   ],
   "source": [
    "# model.model_.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)\n",
    "# print(decode(model.model_.generate(data, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(input_text):\n",
    "    encoded_input_text = encode(input_text)\n",
    "    data = torch.tensor([encoded_input_text], dtype=torch.long)\n",
    "    return decode(model.model_.generate(data, max_new_tokens=500)[0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hi there spelldeiuserererioul, t.\\n\\n\\n\\n ta che I pousp the tse wed tof tome tone ishe w tshe ine tthe e---p the\\n\\nsp p she one the buse tref--\\n\\n'sspsh; thinse affe te me t t w my ho sp e the thee d- itw\\n\\n\\n\\n\\nithe;\\n\\n yonese eathane the os sptoust me tod te s----\\n\\n\\nstease twe a the tofoos tone se timse spse to\\n\\nare tse he the mpoure t he te t se a ite csp im; ts.\\nbe e a the t y wow twic itsse sse eHe ine tshe y ne are w w- chosp-Se\\n one me se i-- spppe tofe te t\\n\\n\\n\\n\\n\\nshele\\nipoufe ne we y thit. che sp me tot t\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_box = gr.Textbox()\n",
    "output_text_box = gr.Textbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "app  = gr.Interface(generate_response,input_text_box,output_text_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('pytorch_model_training')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "639cd7b51718eb79982c53fc18e7f7b25ec7e9a2a775b00e4c4cd00fb053d272"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
